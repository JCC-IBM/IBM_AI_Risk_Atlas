# Data Bias risk for AI

 **Risks associated with input** \
 **Training and tuning phase** \
 **Fairness** \
 **Amplified by generative AI**

### Description

Historical, representational, and societal biases present in the data used to train and fine tune the model can adversely affect model behavior.

### Why is data bias a concern for foundation models?

Training an AI system on data with bias, such as historical or representational bias, could lead to biased or skewed outputs that may unfairly represent or otherwise discriminate against certain groups or individuals. In addition to negative societal impacts, business entities could face legal consequences or reputational harms from biased model outcomes.

### Example - Healthcare Bias

According to the research article on reinforcing disparities in medicine using data and AI applications to transform how people receive healthcare is only as strong as the data behind the effort. For example, using training data with poor minority representation or that reflects what is already unequal care can lead to increased health inequalities.

Source: https://www.forbes.com/sites/adigaskell/2022/12/02/minority-patients-often-left-behind-by-health-ai/?sh=31d28a225b41