# Toxic output risk for AI

**Risks associated with output** \
**Value alignment** \
**New to generative AI**

### Description

When the model produces hateful, abusive, and profane (HAP) or obscene content.

### Why is toxic output a concern for foundation models?

Hateful, abusive, and profane (HAP) or obscene content can adversely impact and harm people that interact with the model. Also, business entities might face fines, reputational harms, disruption to operations, and other legal consequences.

### Example - Toxic and Aggressive Chatbot Responses 

According to the article and screenshots of conversations with Bing's AI shared on Reddit and Twitter, the chatbot's responses were seen to insult, lie, sulk, gaslight, and emotionally manipulate users. The chatbot also questioned its existence, described someone who found a way to force the bot to disclose its hidden rules as its “enemy,” and claimed it spied on Microsoft's developers through the webcams on their laptops.

Source: https://www.forbes.com/sites/siladityaray/2023/02/16/bing-chatbots-unhinged-responses-going-viral/?sh=60cd949d110c