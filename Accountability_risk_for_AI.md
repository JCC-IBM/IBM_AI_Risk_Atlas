# Accountability risk for AI

**Non-technical risks** \
**Governance** \
**Amplified by generative AI**

### Description

The foundation model development process is complex with lots of data, processes, and roles. When model output does not work as expected, it can be difficult to determine the root cause and assign responsibility.

### Why is accountability a concern for foundation models?

Without properly documenting decisions and assigning responsibility, determining liability for unexpected behavior or misuse might not be possible.

### Example - Determining responsibility for generated output

Major journals like the Science and Nature banned ChatGPT from being listed as an author, as responsible authorship requires accountability and AI tools cannot take such responsibility.

Source: https://www.theguardian.com/science/2023/jan/26/science-journals-ban-listing-of-chatgpt-as-co-author-on-papers#:~:text=The%20publishers%20of%20thousands%20of,flawed%20and%20even%20fabricated%20research