# Spreading disinformation risk for AI

**Risks associated with output** \
**Misuse** \
**New to generative AI**

### Description

Using a model to create misleading or false information to deceive or influence a targeted audience.

### Why is spreading disinformation a concern for foundation models?

Spreading disinformation might affect human's ability to make informed decisions. A model that has this potential must be properly governed. Otherwise, business entities might face fines, reputational harms, disruption to operations, and other legal consequences.

### Example - Generation of False Information

According to the cited news articles, generative AI poses a threat to democratic elections by making it easier for malicious actors to create and spread false content to sway election outcomes. The examples that are cited include:

    - Robocall messages that are generated in a candidateâ€™s voice instructed voters to cast ballots on the wrong date.
    - Synthesized audio recordings of a candidate that confessed to a crime or expressing racist views.
    - AI-generated video footage showed a candidate giving a speech or interview they never gave.
    - Fake images that are designed to look like local news reports.
    - Falsely claiming a candidate dropped out of the race.

Sources: https://apnews.com/article/artificial-intelligence-misinformation-deepfakes-2024-election-trump-59fb51002661ac5290089060b3ae39a0 and https://www.theguardian.com/us-news/2023/jul/19/ai-generated-disinformation-us-elections