# AI risk atlas

Explore this atlas to understand some of the risks of working with generative AI, foundation models, and machine learning models.

Risks are categorized with one of these tags:

- Traditional AI risks (applies to traditional models as well as generative AI)
- Risks amplified by generative AI (might also apply to traditional models)
- New risks specifically associated with generative AI

### Risks associated with input

#### Training and tuning phase

* Fairness
    * Data Bias. Amplified.

* Robustness
    * Data poisoning. Traditional.

* Value alignment
    * Data curation. Amplified.
    * Downstream retraining. New.

* Data laws
    * Data transfer. Traditional.
    * Data usage. Traditional.
    * Data acquisition. Amplified.

* Intellectual property
    * Data usage rights. Amplified.
    * Confidential information in data. Traditional.

* Transparency
    * Data transparency. Amplified.
    * Data provenance. Amplified.

 * Privacy
    * Personal information in data. Traditional.
    * Reidentification. Traditional.
    * Data privacy rights. Amplified.
    * Informed consent. Traditional.

#### Inference phase

* Privacy
    * Personal information in prompt. New.
    * Membership inference attack. Traditional.
    * Attribute inference attack Amplified

* Intellectual property
    * IP information in prompt. New.
    * Confidential data in prompt. New.

* Robustness
    * Evasion attack. Amplified.
    * Extraction attack. Amplified.
    * Prompt injection. New.
    * Prompt leaking. Amplified.

* Multi-category
    * Prompt priming. Amplified.
    * Jailbreaking. Amplified.

### Risks associated with output

* Fairness
    * Output bias. New.
    * Decision bias. Traditional.

* Intellectual property
    * Copyright infringement. New.
    * Revealing confidential information. Amplified.

* Value alignment
    * Hallucination. New.
    * Toxic output. New.
    * Over or under reliance. Amplified.
    * Physical harm. New.
    * Unspecified advice. New.

* Misuse
    * Spreading disinformation. New.
    * Spreading toxicity. New.
    * Nonconsensual use. Amplified.
    * Dangerous use. New.
    * Non-disclosure. New.
    * Improper usage. Amplified.

* Harmful code generation
    * Harmful code generation. New.

* Privacy
    * Revealing personal information. Amplified.

* Explainability
    * Unexplainable output. Amplified.
    * Unreliable source attribution. Amplified.
    * Inaccessible training data. Amplified.
    * Untraceable attribution. Amplified.

### Non-technical risks

* Governance
    * Lack of model transparency. Traditional.
    * Lack of data transparency. Amplified.
    * Accountability. Amplified.

* Legal compliance
    * Legal accountability. New.
    * Generated content ownership. New.
    * Generated content IP. New.

* Societal impact
    * Job loss. Amplified.
    * Human exploitation. Amplified.
    * Impact on the environment. Amplified.
    * Impact on cultural diversity. New.
    * Impact on human agency. Amplified.
    * Bypassing learning. New.
    * Plagiarism. New.