# Nonconsensual use risk for AI

**Risks associated with output** \
**Misuse** \
**Amplified by generative AI**

### Description

Using a model to imitate people through video (deepfakes), images, audio, or other modalities without their consent.

### Why is nonconsensual use a concern for foundation models?

Deepfakes can spread disinformation about a person, possibly resulting in a negative impact on the person’s reputation. A model that has this potential must be properly governed. Otherwise, business entities might face fines, reputational harms, disruption to operations, and other legal consequences.

### Example - FBI Warning on Deepfakes

The FBI recently warned the public of malicious actors creating synthetic, explicit content “for the purposes of harassing victims or sextortion schemes”. They noted that advancements in AI made this content higher quality, more customizable, and more accessible than ever.

Source: https://www.ic3.gov/Media/Y2023/PSA230605

### Example - Audio Deepfakes

According to the source article, the Federal Communications Commission outlawed robocalls that contain voices that are generated by artificial intelligence. The announcement came after AI-generated robocalls mimicked the President's voice to discourage people from voting in the state's first-in-the-nation primary.

Source: https://apnews.com/article/fcc-elections-artificial-intelligence-robocalls-regulations-a8292b1371b3764916461f60660b93e6