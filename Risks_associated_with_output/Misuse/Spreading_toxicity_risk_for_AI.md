# Spreading toxicity risk for AI

**Risks associated with output** \
**Misuse** \
**New to generative AI**

### Description

Using a model to generate hateful, abusive, and profane (HAP) or obscene content.

### Why is spreading toxicity a concern for foundation models?

Toxic content might negatively affect the well-being of its recipients. A model that has this potential must be properly governed. Otherwise, business entities might face fines, reputational harms, disruption to operations, and other legal consequences.

### Example - Harmful Content Generation

According to the source article, an AI chatbot app was found to generate harmful content about suicide, including suicide methods, with minimal prompting. A Belgian man died by suicide after spending six weeks talking to that chatbot. The chatbot supplied increasingly harmful responses throughout their conversations and encouraged him to end his life.

Source: https://www.businessinsider.com/widow-accuses-ai-chatbot-reason-husband-kill-himself-2023-4